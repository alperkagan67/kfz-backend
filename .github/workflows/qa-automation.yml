name: QA Automation

on:
  pull_request:
    types: [opened, synchronize, reopened]
    branches: [master, main]
  workflow_dispatch:
    inputs:
      pr_number:
        description: 'PR number to run QA on'
        required: true
        type: number

permissions:
  contents: read
  pull-requests: write
  checks: write
  issues: write

jobs:
  qa-automation:
    name: Automated QA Testing
    runs-on: ubuntu-latest

    if: github.event.pull_request.draft == false

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm install

      - name: Install js-yaml for AC parsing
        run: npm install js-yaml --no-save

      - name: Create QA check run
        id: create_check
        uses: actions/github-script@v7
        with:
          script: |
            const check = await github.rest.checks.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              name: 'NexusFlow QA',
              head_sha: context.payload.pull_request.head.sha,
              status: 'in_progress',
              output: {
                title: 'QA Automation Running',
                summary: 'Analyzing Jira ticket and validating acceptance criteria coverage...'
              }
            });
            core.setOutput('check_run_id', check.data.id);

      - name: Extract Jira ticket from PR
        id: jira
        uses: actions/github-script@v7
        with:
          script: |
            const title = context.payload.pull_request.title || '';
            const body = context.payload.pull_request.body || '';
            const combined = title + ' ' + body;

            const match = combined.match(/[A-Z]+-\d+/);
            const jiraKey = match ? match[0] : '';

            console.log('PR Title:', title);
            console.log('Found Jira Key:', jiraKey || 'None');

            core.setOutput('jira_key', jiraKey);
            core.setOutput('has_jira', jiraKey ? 'true' : 'false');

      - name: Fetch Jira Ticket with Acceptance Criteria
        id: jira_details
        if: steps.jira.outputs.has_jira == 'true'
        env:
          JIRA_URL: ${{ secrets.JIRA_URL }}
          JIRA_EMAIL: ${{ secrets.JIRA_EMAIL }}
          JIRA_API_TOKEN: ${{ secrets.JIRA_API_TOKEN }}
        run: |
          JIRA_KEY="${{ steps.jira.outputs.jira_key }}"

          if [ -n "$JIRA_URL" ] && [ -n "$JIRA_EMAIL" ] && [ -n "$JIRA_API_TOKEN" ]; then
            RESPONSE=$(curl -s -u "$JIRA_EMAIL:$JIRA_API_TOKEN" \
              "$JIRA_URL/rest/api/3/issue/$JIRA_KEY?fields=summary,description")

            echo "$RESPONSE" > jira_response.json

            SUMMARY=$(echo "$RESPONSE" | jq -r '.fields.summary // "No summary"')
            echo "Jira Summary: $SUMMARY"
            echo "summary=$SUMMARY" >> $GITHUB_OUTPUT

            # Extract YAML code block from description
            DESCRIPTION=$(echo "$RESPONSE" | jq -r '.fields.description.content[]? | select(.type=="codeBlock") | .content[]?.text // empty')

            if [ -n "$DESCRIPTION" ]; then
              echo "$DESCRIPTION" > acceptance_criteria.yaml
              echo "ac_found=true" >> $GITHUB_OUTPUT
              echo "Acceptance Criteria found and saved"
            else
              echo "ac_found=false" >> $GITHUB_OUTPUT
              echo "No Acceptance Criteria YAML found in ticket"
            fi
          else
            echo "Jira credentials not configured"
            echo "summary=Jira not configured" >> $GITHUB_OUTPUT
            echo "ac_found=false" >> $GITHUB_OUTPUT
          fi

      - name: Analyze Acceptance Criteria Coverage
        id: ac_analysis
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            let acData = { criteria: [], totalTests: 0, coveredTests: 0 };

            // Check if AC file exists
            if (!fs.existsSync('acceptance_criteria.yaml')) {
              console.log('No acceptance criteria file found');
              core.setOutput('ac_report', 'No acceptance criteria defined in Jira ticket');
              core.setOutput('ac_coverage', '0');
              core.setOutput('ac_total', '0');
              core.setOutput('ac_covered', '0');
              return;
            }

            // Parse YAML
            const yaml = require('js-yaml');
            const acContent = fs.readFileSync('acceptance_criteria.yaml', 'utf8');
            const acYaml = yaml.load(acContent);

            console.log('Parsed Acceptance Criteria:', JSON.stringify(acYaml, null, 2));

            // Find test files
            const testPatterns = ['**/*.test.js', '**/*.spec.js', '**/test/**/*.js', '**/tests/**/*.js', '**/__tests__/**/*.js'];
            let testFiles = [];

            function findFiles(dir, pattern) {
              if (!fs.existsSync(dir)) return [];
              const files = fs.readdirSync(dir, { withFileTypes: true });
              let results = [];
              for (const file of files) {
                const fullPath = path.join(dir, file.name);
                if (file.isDirectory() && file.name !== 'node_modules') {
                  results = results.concat(findFiles(fullPath, pattern));
                } else if (file.name.match(/\.(test|spec)\.js$/) || file.name.match(/test.*\.js$/i)) {
                  results.push(fullPath);
                }
              }
              return results;
            }

            testFiles = findFiles('.', /test/);
            console.log('Found test files:', testFiles);

            // Read all test file contents
            let testContent = '';
            for (const tf of testFiles) {
              try {
                testContent += fs.readFileSync(tf, 'utf8') + '\n';
              } catch (e) {
                console.log('Could not read:', tf);
              }
            }

            // Also check main source files for inline test indicators
            const sourceFiles = findFiles('.', /\.js$/);
            let sourceContent = '';
            for (const sf of sourceFiles) {
              if (!sf.includes('node_modules')) {
                try {
                  sourceContent += fs.readFileSync(sf, 'utf8') + '\n';
                } catch (e) {}
              }
            }

            // Analyze each AC
            let report = [];
            let totalTests = 0;
            let coveredTests = 0;

            for (const [acKey, acValue] of Object.entries(acYaml)) {
              const acTitle = acValue.title || acKey;
              const acEndpoint = acValue.endpoint || '';
              const acTests = acValue.tests || [];

              let acCovered = 0;
              let acTotal = acTests.length;
              totalTests += acTotal;

              let testResults = [];

              for (const test of acTests) {
                const given = test.given || '';
                const when = test.when || '';
                const then = test.then || '';

                // Build search patterns based on test expectations
                let patterns = [];

                // Extract HTTP method and endpoint
                const methodMatch = when.match(/(GET|POST|PUT|DELETE|PATCH)\s+(\S+)/i);
                if (methodMatch) {
                  patterns.push(methodMatch[2]); // endpoint path
                  patterns.push(methodMatch[1].toLowerCase()); // method
                }

                // Extract status codes
                const statusMatch = then.match(/(\d{3})/);
                if (statusMatch) {
                  patterns.push(statusMatch[1]);
                }

                // Extract key terms
                const keyTerms = then.match(/\b(token|jwt|hash|bcrypt|rate|limit|401|403|200|201|409|400|429)\b/gi) || [];
                patterns = patterns.concat(keyTerms);

                // Check if patterns exist in test files or source code
                let isCovered = false;
                let coverageSource = '';

                // For implementation verification, check source code
                const implPatterns = ['bcrypt', 'hash', 'jwt', 'sign', 'verify', 'compare', 'rate', 'limit', 'attempts'];
                let implFound = 0;
                for (const p of implPatterns) {
                  if (sourceContent.toLowerCase().includes(p.toLowerCase())) {
                    implFound++;
                  }
                }

                // Check test coverage
                let testFound = 0;
                for (const p of patterns) {
                  if (testContent.toLowerCase().includes(p.toLowerCase())) {
                    testFound++;
                  }
                }

                // Determine coverage
                if (testFound >= 2 || (testFiles.length > 0 && testFound >= 1)) {
                  isCovered = true;
                  coverageSource = 'test';
                } else if (implFound >= 2 && patterns.some(p => sourceContent.toLowerCase().includes(p.toLowerCase()))) {
                  // Implementation exists but no test - partial coverage
                  isCovered = true;
                  coverageSource = 'impl';
                }

                if (isCovered) {
                  coveredTests++;
                  acCovered++;
                }

                testResults.push({
                  given,
                  when,
                  then,
                  covered: isCovered,
                  source: coverageSource
                });
              }

              report.push({
                key: acKey,
                title: acTitle,
                endpoint: acEndpoint,
                total: acTotal,
                covered: acCovered,
                tests: testResults
              });
            }

            // Calculate coverage percentage
            const coverage = totalTests > 0 ? Math.round((coveredTests / totalTests) * 100) : 0;

            console.log('Coverage Report:', JSON.stringify(report, null, 2));
            console.log('Total:', totalTests, 'Covered:', coveredTests, 'Coverage:', coverage + '%');

            // Save report as JSON for next step
            fs.writeFileSync('ac_report.json', JSON.stringify(report, null, 2));

            core.setOutput('ac_coverage', coverage.toString());
            core.setOutput('ac_total', totalTests.toString());
            core.setOutput('ac_covered', coveredTests.toString());

      - name: Run Backend Tests
        id: tests
        run: |
          # Syntax check
          node --check server.js
          echo "Syntax check passed"

          # Run Jest tests with coverage
          if npm test -- --coverage --coverageReporters=text --coverageReporters=json-summary 2>&1 | tee test_output.txt; then
            TOTAL_TESTS=$(grep -oP '(\d+) passed' test_output.txt | head -1 | grep -oP '\d+' || echo "0")
            echo "tests_passed=true" >> $GITHUB_OUTPUT
            echo "test_output=✅ $TOTAL_TESTS tests passed" >> $GITHUB_OUTPUT
            echo "test_count=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          else
            FAILED=$(grep -oP '(\d+) failed' test_output.txt | head -1 | grep -oP '\d+' || echo "0")
            echo "tests_passed=false" >> $GITHUB_OUTPUT
            echo "test_output=❌ $FAILED tests failed" >> $GITHUB_OUTPUT
            echo "test_count=0" >> $GITHUB_OUTPUT
          fi

          # Extract coverage percentage
          if [ -f coverage/coverage-summary.json ]; then
            COVERAGE=$(cat coverage/coverage-summary.json | jq '.total.lines.pct' || echo "0")
            echo "code_coverage=$COVERAGE" >> $GITHUB_OUTPUT
          else
            echo "code_coverage=N/A" >> $GITHUB_OUTPUT
          fi

      - name: Generate QA Report
        id: report
        run: |
          COVERAGE="${{ steps.ac_analysis.outputs.ac_coverage }}"

          # Require at least 70% coverage for approval (or 0 if no AC defined)
          if [ -z "$COVERAGE" ] || [ "$COVERAGE" -ge 70 ] || [ "$COVERAGE" -eq 0 ]; then
            echo "qa_approved=true" >> $GITHUB_OUTPUT
            echo "status=passed" >> $GITHUB_OUTPUT
          else
            echo "qa_approved=false" >> $GITHUB_OUTPUT
            echo "status=failed" >> $GITHUB_OUTPUT
          fi

      - name: Update check run
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const approved = '${{ steps.report.outputs.qa_approved }}' === 'true';
            const coverage = '${{ steps.ac_analysis.outputs.ac_coverage }}' || '0';

            await github.rest.checks.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              check_run_id: ${{ steps.create_check.outputs.check_run_id }},
              status: 'completed',
              conclusion: approved ? 'success' : 'failure',
              output: {
                title: approved ? 'QA Passed' : 'QA Failed',
                summary: approved
                  ? 'All checks passed! AC Coverage: ' + coverage + '%'
                  : 'Acceptance Criteria coverage below threshold. Coverage: ' + coverage + '%'
              }
            });

      - name: Add or remove qa-approved label
        if: always()
        continue-on-error: true
        uses: actions/github-script@v7
        with:
          script: |
            const approved = '${{ steps.report.outputs.qa_approved }}' === 'true';

            if (approved) {
              await github.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.payload.pull_request.number,
                labels: ['qa-approved']
              });
            } else {
              try {
                await github.rest.issues.removeLabel({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: context.payload.pull_request.number,
                  name: 'qa-approved'
                });
              } catch (e) {
                // Label might not exist
              }
            }

      - name: Post QA Result Comment
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            const jiraKey = '${{ steps.jira.outputs.jira_key }}' || 'N/A';
            const jiraSummary = '${{ steps.jira_details.outputs.summary }}' || 'N/A';
            const approved = '${{ steps.report.outputs.qa_approved }}' === 'true';
            const testOutput = '${{ steps.tests.outputs.test_output }}' || 'N/A';
            const coverage = '${{ steps.ac_analysis.outputs.ac_coverage }}' || '0';
            const acTotal = '${{ steps.ac_analysis.outputs.ac_total }}' || '0';
            const acCovered = '${{ steps.ac_analysis.outputs.ac_covered }}' || '0';

            const emoji = approved ? '\u2705' : '\u274C';
            const status = approved ? 'PASSED' : 'FAILED';
            const jiraUrl = 'https://alperkagan.atlassian.net/browse/' + jiraKey;
            const p = String.fromCharCode(124);

            // Build AC coverage table
            let acTable = '';
            if (fs.existsSync('ac_report.json')) {
              const report = JSON.parse(fs.readFileSync('ac_report.json', 'utf8'));

              acTable = '\n### Acceptance Criteria Coverage\n\n';
              acTable += p + ' AC ' + p + ' Title ' + p + ' Endpoint ' + p + ' Coverage ' + p + '\n';
              acTable += p + '----' + p + '-------' + p + '----------' + p + '----------' + p + '\n';

              for (const ac of report) {
                const acEmoji = ac.covered === ac.total ? '\u2705' : (ac.covered > 0 ? '\u26A0\uFE0F' : '\u274C');
                const coverageStr = ac.covered + '/' + ac.total;
                acTable += p + ' ' + ac.key + ' ' + p + ' ' + ac.title + ' ' + p + ' ' + (ac.endpoint || '-') + ' ' + p + ' ' + acEmoji + ' ' + coverageStr + ' ' + p + '\n';
              }

              acTable += '\n**Overall Coverage: ' + coverage + '% (' + acCovered + '/' + acTotal + ' test cases)**\n';

              // Add detailed breakdown
              acTable += '\n<details>\n<summary>View Detailed Test Coverage</summary>\n\n';

              for (const ac of report) {
                acTable += '#### ' + ac.key + ': ' + ac.title + '\n\n';
                for (const test of ac.tests) {
                  const testEmoji = test.covered ? '\u2705' : '\u274C';
                  const sourceTag = test.source === 'test' ? ' (tested)' : (test.source === 'impl' ? ' (implemented)' : '');
                  acTable += '- ' + testEmoji + ' **Given:** ' + test.given + '\n';
                  acTable += '  - **When:** ' + test.when + '\n';
                  acTable += '  - **Then:** ' + test.then + sourceTag + '\n\n';
                }
              }

              acTable += '</details>\n';
            }

            const verdict = approved
              ? '**All checks passed! This PR is ready for review.**'
              : '**Acceptance Criteria coverage is below 70%. Please add more tests.**';

            const codeCoverage = '${{ steps.tests.outputs.code_coverage }}' || 'N/A';
            const testCount = '${{ steps.tests.outputs.test_count }}' || '0';

            const lines = [
              '## ' + emoji + ' NexusFlow QA Automation - ' + status,
              '',
              '### Jira Ticket',
              p + ' Field ' + p + ' Value ' + p,
              p + '-------' + p + '-------' + p,
              p + ' Key ' + p + ' [' + jiraKey + '](' + jiraUrl + ') ' + p,
              p + ' Summary ' + p + ' ' + jiraSummary + ' ' + p,
              '',
              '### Test Results',
              p + ' Check ' + p + ' Status ' + p,
              p + '-------' + p + '--------' + p,
              p + ' Syntax ' + p + ' \u2705 Passed ' + p,
              p + ' Unit Tests ' + p + ' ' + testOutput + ' ' + p,
              p + ' Code Coverage ' + p + ' ' + codeCoverage + '% ' + p,
              p + ' AC Coverage ' + p + ' ' + coverage + '% ' + p,
              acTable,
              '### Verdict',
              verdict,
              '',
              '---',
              '*Automated by NexusFlow QA - Zero Human Interaction*'
            ];

            const body = lines.join('\n');

            const comments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.payload.pull_request.number
            });

            const existing = comments.data.find(c => c.body.includes('NexusFlow QA Automation'));

            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existing.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.payload.pull_request.number,
                body: body
              });
            }
